import os
import json
import shutil
from datetime import datetime
from pytz import timezone

PREDICTIONS_DIR = "predicted_future"
REPORTS_DIR = "daily_reports"
DOCS_INDEX_PATH = "docs/index.md"
HTML_INDEX_PATH = "index.html"

def load_latest_prediction():
    """æœ€æ–°ã®äºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å†…ã®æ—¥ä»˜ã‚‚è¿”ã™ï¼‰"""
    json_files = [
        f for f in os.listdir(PREDICTIONS_DIR) if f.endswith(".json")
    ]

    def extract_date(filename):
        try:
            return datetime.strptime(filename.split("_")[0], "%Y-%m-%d")
        except ValueError:
            return datetime.min

    sorted_files = sorted(json_files, key=extract_date, reverse=True)

    for file in sorted_files:
        path = os.path.join(PREDICTIONS_DIR, file)
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, list) and len(data) > 0:
                return data, data[0].get("date", "unknown")
    return None, None

def generate_report_content(prediction_data, report_date):
    if isinstance(prediction_data, list) and len(prediction_data) > 0:
        first_item = prediction_data[0]
        category = first_item.get("category", "ãã®ä»–")
        summary = first_item.get("summary", "æ¦‚è¦ãªã—")
        prediction = first_item.get("prediction", "äºˆæ¸¬å†…å®¹ãªã—")
    else:
        category = "ãã®ä»–"
        summary = "æ¦‚è¦ãªã—"
        prediction = "äºˆæ¸¬å†…å®¹ãªã—"

    return f"""\
ã€æœªæ¥äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆã€‘ğŸ“… {report_date}

ğŸ—‚ ã‚«ãƒ†ã‚´ãƒª: {category}

ğŸ“ è¦ç´„:
{summary}

ğŸ”® æœªæ¥äºˆæ¸¬:
{prediction}

---

ğŸ§  powered by NOVAï½œæœªæ¥äºˆæ¸¬AI
"""

def save_report(content, report_date):
    os.makedirs(REPORTS_DIR, exist_ok=True)
    filename = f"report_{report_date}_predictions.txt"
    path = os.path.join(REPORTS_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"[âœ…] ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {path}")
    return path

def generate_html_report(txt_content):
    html = """<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <title>æœªæ¥äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆï½œNOVA</title>
    <style>
        body { font-family: sans-serif; line-height: 1.8; margin: 2em; background: #f9f9f9; }
        h1 { color: #333; }
        p { margin-bottom: 1em; }
    </style>
</head>
<body>
"""
    for line in txt_content.splitlines():
        if line.strip() == "":
            html += "<br>\n"
        elif line.startswith("ã€"):
            html += f"<h1>{line}</h1>\n"
        else:
            html += f"<p>{line}</p>\n"
    html += '<div style="margin-top:2em;font-size:0.9em;color:#666;">ğŸ§  powered by NOVAï½œæœªæ¥äºˆæ¸¬AI</div>\n</body>\n</html>'
    return html

def main():
    data, report_date = load_latest_prediction()
    if not data:
        print("[âš ï¸] äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    content = generate_report_content(data, report_date)
    output_path = save_report(content, report_date)

    shutil.copyfile(output_path, DOCS_INDEX_PATH)
    print(f"[ğŸ“„] docs/index.md ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸã€‚")

    html = generate_html_report(content)
    with open(HTML_INDEX_PATH, "w", encoding="utf-8") as f:
        f.write(html)
    print(f"[ğŸŒ] HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ: {HTML_INDEX_PATH}")

if __name__ == "__main__":
    main()
