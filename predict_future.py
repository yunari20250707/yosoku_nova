import os
import json
from datetime import datetime
from transformers import pipeline
import torch

# âœ… è¨­å®š
today = datetime.now().strftime("%Y-%m-%d")
input_path = f"classified_articles/{today}_classified.json"
output_path = f"predicted_future/{today}_predictions.json"

# âœ… ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = 0 if torch.backends.mps.is_available() else -1
print(f"ğŸ”® æœªæ¥äºˆæ¸¬ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹ï¼ˆãƒ‡ãƒã‚¤ã‚¹: {'mps' if device == 0 else 'CPU'}ï¼‰")

# âœ… æœªæ¥äºˆæ¸¬ç”¨ã®ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆgpt2-mediumï¼‰
generator = pipeline("text-generation", model="gpt2-medium", device=device)

# âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
if not os.path.exists(input_path):
    raise FileNotFoundError(f"ğŸ›‘ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_path}")

with open(input_path, "r", encoding="utf-8") as f:
    articles = json.load(f)

# âœ… å‡ºåŠ›çµæœæ ¼ç´ç”¨
predictions = []

for item in articles:
    title = item.get("title", "")
    content = item.get("summary", "")
    category = item.get("category", "unknown")

    prompt = (
        f"ã‚«ãƒ†ã‚´ãƒª: {category}\n"
        f"ã‚¿ã‚¤ãƒˆãƒ«: {title}\n"
        f"è¦ç´„: {content}\n\n"
        f"ã“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰å°ãå‡ºã•ã‚Œã‚‹ä»Šå¾Œã®æœªæ¥äºˆæ¸¬ã¯ï¼Ÿ:\n"
    )

    try:
        result = generator(prompt, max_length=150, do_sample=True, temperature=0.7)[0]["generated_text"]
        prediction = result.split("ã“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰å°ãå‡ºã•ã‚Œã‚‹ä»Šå¾Œã®æœªæ¥äºˆæ¸¬ã¯ï¼Ÿ:")[-1].strip()

        predictions.append({
            "title": title,
            "category": category,
            "summary": content,
            "prediction": prediction
        })

    except Exception as e:
        print(f"âš ï¸ äºˆæ¸¬å¤±æ•—: {e}")
        continue

# âœ… ä¿å­˜
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(predictions, f, ensure_ascii=False, indent=2)

print(f"âœ… æœªæ¥äºˆæ¸¬å®Œäº† â†’ {output_path}")
