import os
import json
from datetime import datetime
from transformers import pipeline

# ğŸ”§ è¦ç´„ãƒ¢ãƒ‡ãƒ«ï¼ˆHugging Faceï¼‰
summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

# ğŸ“… æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•å–å¾—ï¼ˆdata/news_articles/ï¼‰
data_dir = "data/news_articles"
files = sorted(os.listdir(data_dir), reverse=True)
latest_file = [f for f in files if f.endswith(".json")][0]
file_path = os.path.join(data_dir, latest_file)

print(f"ğŸ§  è¦ç´„å‡¦ç†å¯¾è±¡: {latest_file}")

# ğŸ”„ èª­ã¿è¾¼ã¿
with open(file_path, "r", encoding="utf-8") as f:
    articles = json.load(f)

# âœ… è¦ç´„å‡¦ç†
summarized = []
for article in articles:
    text = article.get("text", "")
    if not text.strip():
        continue

    try:
        summary = summarizer(text[:1024], max_length=120, min_length=30, do_sample=False)[0]["summary_text"]
    except Exception as e:
        print(f"âš ï¸ è¦ç´„ã‚¨ãƒ©ãƒ¼: {article.get('title', '')} â†’ {e}")
        summary = ""

    summarized.append({
        "title": article.get("title", ""),
        "url": article.get("url", ""),
        "published": article.get("published", ""),
        "summary": summary
    })

# ğŸ’¾ ä¿å­˜å…ˆ
output_dir = "summarized_articles"
os.makedirs(output_dir, exist_ok=True)

out_path = os.path.join(output_dir, latest_file.replace("rss_articles", "summaries"))
with open(out_path, "w", encoding="utf-8") as f:
    json.dump(summarized, f, ensure_ascii=False, indent=2)

print(f"âœ… è¦ç´„å®Œäº† â†’ {out_path}")
